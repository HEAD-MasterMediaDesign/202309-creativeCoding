<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport"
          content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>app</title>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
    <script src="http://127.0.0.1:8081/socket.io/socket.io.js"></script>
</head>
<body
>

<button
        class="run-ml"
        type="button"
        onclick="init()"
>Start ML</button>

<div
        class="state-simulation"
>
    <button onclick="socket.emit('message', '3');">neutre</button>
    <button onclick="socket.emit('message', '2');">micro</button>
    <button onclick="socket.emit('message', '0');">smartphone</button>
    <button onclick="socket.emit('message', '1');">credit card</button>
</div>


</body>

<script>
    const socket = io('http://127.0.0.1:8081')
    socket.on('connect', () => {
        socket.emit('config',
            {
                server: {
                    port: 3333,
                    host: '127.0.0.1'
                },
                client: {
                    port: 3334,
                    host: '127.0.0.1'
                }
            }
        )
    })
</script>

<div id="webcam-container"></div>
<div id="label-container"></div>

<script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    const URL = "./";

    let model, webcam, labelContainer, maxPredictions;

    // Load the image model and setup the webcam
    /**
     * @returns {Promise<void>}
     */
    async function init() {
        document.body.classList.add('ml-is-running')
        const modelURL = URL + "model.json"
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }
    }

    let predictValueToSend = ''

    async function loop() {
        webcam.update(); // update the webcam frame
        const predictValue = await predict();

        if(predictValueToSend !== predictValue) {
            predictValueToSend = predictValue
            if(predictValueToSend === 'Micro') {
                console.log('---> Micro', 2)
                socket.emit('message', '2')
            }
            else if(predictValueToSend === 'Smartphone') {
                console.log('---> Smartphone', 0)
                socket.emit('message', '0')
            }
            else if(predictValueToSend === 'Credit card') {
                console.log('---> Credit card', 1)
                socket.emit('message', '1')
            }
            else if(predictValueToSend === 'Neutre') {
                console.log('---> Neutre', 3)
                socket.emit('message', '3')
            }
        }


         window.requestAnimationFrame(loop);
    }

    // run the webcam image through the image model
    /**
     * @returns {Promise<string>}
     */
    async function predict() {
        // predict can take in an image, video or canvas html element
        /**
         * @var {Array}
         */
        const prediction = await model.predict(webcam.canvas);
        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction =
                prediction[i].className + ": " + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
        }
        let maxValue = 0
        let classNameToReturn = ''

        prediction.map((value) => {
            if (value.probability.toFixed(2) > maxValue) {
                maxValue = value.probability.toFixed(2)
                classNameToReturn = value.className
            }
        })
        return classNameToReturn
    }
</script>

<style>
    .state-simulation {
        display: none;
    }

    .ml-is-running .run-ml {
        display: none;
    }

    .ml-is-running .state-simulation {
        display: block;
    }
</style>

</html>
